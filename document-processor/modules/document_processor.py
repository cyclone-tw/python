#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å…¬æ–‡è™•ç†å™¨ - PDFå…§å®¹æå–èˆ‡çµæ§‹åŒ–
åŸºæ–¼åŸæœ‰ pdf_processor.py å„ªåŒ–ï¼Œå°ˆæ³¨æ–¼å…§å®¹æå–
"""

import re
import os
from pathlib import Path
from typing import Dict, List, Optional, Tuple
from datetime import datetime

try:
    import pdfplumber
    PDF_AVAILABLE = True
except ImportError:
    PDF_AVAILABLE = False
    print("âš ï¸ pdfplumber æœªå®‰è£ï¼Œè«‹åŸ·è¡Œ: pip install pdfplumber")

from config import SETTINGS


class DocumentProcessor:
    """å…¬æ–‡è™•ç†å™¨"""

    def __init__(self):
        self.noise_patterns = SETTINGS['pdf_processing']['noise_patterns']
        self.section_patterns = SETTINGS['pdf_processing']['section_patterns']

    def process_pdf(self, pdf_path: str) -> Optional[Dict]:
        """è™•ç†PDFæª”æ¡ˆï¼Œæå–çµæ§‹åŒ–å…§å®¹"""
        if not PDF_AVAILABLE:
            print("âŒ pdfplumber å¥—ä»¶æœªå®‰è£")
            return None

        if not os.path.exists(pdf_path):
            print(f"âŒ æª”æ¡ˆä¸å­˜åœ¨: {pdf_path}")
            return None

        try:
            print(f"ğŸ” æ­£åœ¨è™•ç†PDF: {os.path.basename(pdf_path)}")

            with pdfplumber.open(pdf_path) as pdf:
                # æå–æ‰€æœ‰æ–‡å­—
                full_text = ""
                page_count = len(pdf.pages)
                print(f"   PDFå…±æœ‰ {page_count} é ")

                for i, page in enumerate(pdf.pages, 1):
                    try:
                        page_text = page.extract_text()
                        if page_text:
                            full_text += page_text + "\n"
                        print(f"   å·²è™•ç†ç¬¬ {i}/{page_count} é ")
                    except Exception as e:
                        print(f"   âš ï¸ ç¬¬ {i} é è™•ç†å¤±æ•—: {e}")
                        continue

                if not full_text.strip():
                    print(f"âš ï¸ PDFç„¡å…§å®¹æˆ–ç„¡æ³•æå–æ–‡å­—: {pdf_path}")
                    return {
                        'file_path': pdf_path,
                        'file_name': os.path.basename(pdf_path),
                        'full_text': '',
                        'sections': {'å…§å®¹': 'ç„¡æ³•æå–æ–‡å­—å…§å®¹'},
                        'dates': [],
                        'attachments': self._find_attachments_by_prefix(pdf_path),
                        'metadata': {},
                        'processed_at': datetime.now().isoformat(),
                        'error': 'ç„¡æ³•æå–PDFæ–‡å­—'
                    }

                print(f"   âœ… æˆåŠŸæå–æ–‡å­—ï¼Œå…± {len(full_text)} å­—å…ƒ")

                # æ¸…ç†æ–‡å­—
                cleaned_text = self._clean_text(full_text)

                # æå–çµæ§‹åŒ–å…§å®¹
                sections = self._extract_sections(cleaned_text)
                dates = self._extract_dates(cleaned_text)
                attachments = self._find_attachments_by_prefix(pdf_path)

                print(f"   âœ… æ‰¾åˆ° {len(sections)} å€‹æ®µè½ï¼Œ{len(dates)} å€‹æ—¥æœŸï¼Œ{len(attachments)} å€‹é™„ä»¶")

                # å»ºç«‹æ–‡ä»¶è³‡è¨Š
                doc_info = {
                    'file_path': pdf_path,
                    'file_name': os.path.basename(pdf_path),
                    'full_text': cleaned_text,
                    'sections': sections,
                    'dates': dates,
                    'attachments': attachments,
                    'metadata': self._extract_metadata(sections),
                    'processed_at': datetime.now().isoformat()
                }

                return doc_info

        except Exception as e:
            print(f"âŒ è™•ç†PDFæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            import traceback
            print(f"   è©³ç´°éŒ¯èª¤: {traceback.format_exc()}")
            return None

    def _clean_text(self, text: str) -> str:
        """æ¸…ç†æ–‡å­—ï¼Œç§»é™¤é›œè¨Š"""
        cleaned = text

        # å¥—ç”¨é›œè¨Šç§»é™¤è¦å‰‡
        for pattern, replacement in self.noise_patterns:
            cleaned = re.sub(pattern, replacement, cleaned, flags=re.MULTILINE)

        # æ¨™æº–åŒ–ç©ºç™½å­—å…ƒ
        cleaned = re.sub(r'\s+', ' ', cleaned)
        cleaned = re.sub(r'\n\s*\n', '\n', cleaned)

        return cleaned.strip()

    def _extract_sections(self, text: str) -> Dict[str, str]:
        """æå–å…¬æ–‡å„æ®µè½"""
        sections = {}

        # åˆ†å‰²æ–‡å­—ç‚ºè¡Œ
        lines = text.split('\n')
        current_section = None
        current_content = []

        for line in lines:
            line = line.strip()
            if not line:
                continue

            # æª¢æŸ¥æ˜¯å¦ç‚ºæ®µè½æ¨™é¡Œ
            section_found = False
            for section_name, pattern in self.section_patterns.items():
                if re.search(pattern, line):
                    # å„²å­˜å‰ä¸€å€‹æ®µè½
                    if current_section and current_content:
                        sections[current_section] = '\n'.join(current_content).strip()

                    # é–‹å§‹æ–°æ®µè½
                    current_section = section_name
                    current_content = []

                    # ç§»é™¤æ®µè½æ¨™é¡Œï¼Œä¿ç•™å…§å®¹
                    content = re.sub(pattern, '', line).strip()
                    if content:
                        current_content.append(content)

                    section_found = True
                    break

            # å¦‚æœä¸æ˜¯æ®µè½æ¨™é¡Œï¼ŒåŠ å…¥ç•¶å‰æ®µè½å…§å®¹
            if not section_found and current_section:
                current_content.append(line)

        # å„²å­˜æœ€å¾Œä¸€å€‹æ®µè½
        if current_section and current_content:
            sections[current_section] = '\n'.join(current_content).strip()

        # å¦‚æœæ²’æœ‰è­˜åˆ¥åˆ°æ®µè½ï¼Œå°‡å…¨æ–‡ä½œç‚ºå…§å®¹
        if not sections:
            sections['å…§å®¹'] = text

        return sections

    def _extract_dates(self, text: str) -> List[Dict]:
        """æå–æ—¥æœŸè³‡è¨Š"""
        dates = []

        # æ°‘åœ‹å¹´æ ¼å¼
        roc_patterns = [
            r'(\d{2,3})\s*å¹´\s*(\d{1,2})\s*æœˆ\s*(\d{1,2})\s*æ—¥',
            r'(\d{2,3})/(\d{1,2})/(\d{1,2})',
            r'(\d{2,3})-(\d{1,2})-(\d{1,2})'
        ]

        for pattern in roc_patterns:
            matches = re.finditer(pattern, text)
            for match in matches:
                try:
                    year = int(match.group(1))
                    month = int(match.group(2))
                    day = int(match.group(3))

                    # åˆ¤æ–·æ—¥æœŸé¡å‹
                    context = text[max(0, match.start()-20):match.end()+20]
                    date_type = self._classify_date_type(context)

                    dates.append({
                        'raw': match.group(0),
                        'year': year,
                        'month': month,
                        'day': day,
                        'type': date_type,
                        'context': context.strip()
                    })
                except ValueError:
                    continue

        # è¥¿å…ƒå¹´æ ¼å¼
        western_patterns = [
            r'(\d{4})\s*å¹´\s*(\d{1,2})\s*æœˆ\s*(\d{1,2})\s*æ—¥',
            r'(\d{4})/(\d{1,2})/(\d{1,2})',
            r'(\d{4})-(\d{1,2})-(\d{1,2})'
        ]

        for pattern in western_patterns:
            matches = re.finditer(pattern, text)
            for match in matches:
                try:
                    year = int(match.group(1)) - 1911  # è½‰ç‚ºæ°‘åœ‹å¹´
                    month = int(match.group(2))
                    day = int(match.group(3))

                    if year > 0:  # ç¢ºä¿æ˜¯åˆç†çš„æ°‘åœ‹å¹´
                        context = text[max(0, match.start()-20):match.end()+20]
                        date_type = self._classify_date_type(context)

                        dates.append({
                            'raw': match.group(0),
                            'year': year,
                            'month': month,
                            'day': day,
                            'type': date_type,
                            'context': context.strip()
                        })
                except ValueError:
                    continue

        # ç§»é™¤é‡è¤‡ä¸¦æ’åº
        unique_dates = []
        seen = set()
        for date in dates:
            key = (date['year'], date['month'], date['day'])
            if key not in seen:
                seen.add(key)
                unique_dates.append(date)

        return sorted(unique_dates, key=lambda x: (x['year'], x['month'], x['day']))

    def _classify_date_type(self, context: str) -> str:
        """åˆ¤æ–·æ—¥æœŸé¡å‹"""
        context_lower = context.lower()

        if any(word in context for word in ['æˆªæ­¢', 'ç¹³äº¤', 'å ±å', 'æ”¶ä»¶']):
            return 'deadline'
        elif any(word in context for word in ['èˆ‰è¾¦', 'è¾¦ç†', 'æ´»å‹•', 'æœƒè­°']):
            return 'event'
        elif any(word in context for word in ['ç™¼æ–‡', 'ä¾†æ–‡']):
            return 'document'
        else:
            return 'general'

    def _extract_metadata(self, sections: Dict[str, str]) -> Dict[str, str]:
        """æå–å…ƒæ•¸æ“š"""
        metadata = {}

        # æå–ç™¼æ–‡å­—è™Ÿ
        for section_name, content in sections.items():
            if 'å­—è™Ÿ' in section_name or 'ç™¼æ–‡å­—è™Ÿ' in section_name:
                metadata['ç™¼æ–‡å­—è™Ÿ'] = content
                break

        # æå–ç™¼æ–‡æ—¥æœŸ
        for section_name, content in sections.items():
            if 'æ—¥æœŸ' in section_name or 'ç™¼æ–‡æ—¥æœŸ' in section_name:
                metadata['ç™¼æ–‡æ—¥æœŸ'] = content
                break

        # æå–å—æ–‡è€…
        if 'å—æ–‡è€…' in sections:
            metadata['å—æ–‡è€…'] = sections['å—æ–‡è€…']

        return metadata

    def _find_attachments_by_prefix(self, pdf_path: str) -> List[Dict]:
        """æ ¹æ“šå®Œæ•´æ–‡ä»¶ç·¨è™Ÿå°‹æ‰¾ç›¸é—œé™„ä»¶ï¼ˆä¿®å¾©ç‰ˆï¼‰"""
        attachments = []
        pdf_path_obj = Path(pdf_path)
        pdf_dir = pdf_path_obj.parent
        pdf_name = pdf_path_obj.name

        # æå–å®Œæ•´æ–‡ä»¶ç·¨è™Ÿï¼Œä¾‹å¦‚å¾ "376480000A_1140221864_print.pdf" æå– "376480000A_1140221864"
        import re
        match = re.match(r'^([A-Za-z0-9]+_[0-9]+)_print\.pdf$', pdf_name)
        if not match:
            # å˜—è©¦ç°¡å–®æ ¼å¼ "ç·¨è™Ÿ_print.pdf"
            match = re.match(r'^([A-Za-z0-9]+)_print\.pdf$', pdf_name)

        if not match:
            print(f"   âš ï¸ æª”åæ ¼å¼ä¸ç¬¦åˆæ¨™æº–æ ¼å¼: {pdf_name}")
            return []

        document_id = match.group(1)  # å®Œæ•´æ–‡ä»¶ç·¨è™Ÿï¼Œå¦‚ "376480000A_1140221864"
        print(f"   ğŸ” å°‹æ‰¾æ–‡ä»¶ç·¨è™Ÿç‚º '{document_id}' çš„é™„ä»¶...")

        # åœ¨åŒç›®éŒ„ä¸‹å°‹æ‰¾ç›¸åŒå®Œæ•´ç·¨è™Ÿçš„é™„ä»¶æª”æ¡ˆ
        try:
            for file_path in pdf_dir.iterdir():
                if not file_path.is_file():
                    continue

                file_name = file_path.name

                # è·³éè‡ªå·±
                if file_name == pdf_name:
                    continue

                # æª¢æŸ¥æ˜¯å¦ç‚ºæ­¤æ–‡ä»¶çš„é™„ä»¶ï¼ˆå¿…é ˆæ˜¯å®Œæ•´åŒ¹é…æ–‡ä»¶ç·¨è™Ÿï¼‰
                # æ­£ç¢ºæ ¼å¼: 376480000A_1140221864_ATTACH1.pdf
                if (file_name.startswith(f"{document_id}_ATTACH") or
                    file_name.startswith(f"{document_id}.") or
                    (file_name.startswith(f"{document_id}_") and not file_name.endswith("_print.pdf"))):

                    attachments.append({
                        'filename': file_name,
                        'path': str(file_path),
                        'size': file_path.stat().st_size,
                        'type': file_path.suffix.lower(),
                        'document_id': document_id
                    })
                    print(f"     âœ… æ‰¾åˆ°é™„ä»¶: {file_name}")

        except Exception as e:
            print(f"   âš ï¸ æœå°‹é™„ä»¶æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")

        print(f"   ğŸ“ å…±æ‰¾åˆ° {len(attachments)} å€‹é™„ä»¶")
        return attachments

    def _find_attachments(self, pdf_path: str) -> List[Dict]:
        """èˆŠç‰ˆé™„ä»¶å°‹æ‰¾æ–¹æ³•ï¼ˆä¿ç•™ç›¸å®¹æ€§ï¼‰"""
        return self._find_attachments_by_prefix(pdf_path)


def test_processor():
    """æ¸¬è©¦è™•ç†å™¨åŠŸèƒ½"""
    processor = DocumentProcessor()

    # é€™è£¡å¯ä»¥åŠ å…¥æ¸¬è©¦ä»£ç¢¼
    print("âœ… DocumentProcessor åˆå§‹åŒ–æˆåŠŸ")


if __name__ == "__main__":
    test_processor()